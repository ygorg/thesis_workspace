\chapter*{Liste des publications}
\addcontentsline{toc}{chapter}{Liste des publications}

\section*{Publication en conférence internationale avec actes}
\addcontentsline{toc}{section}{Publication en conférence internationale avec actes}

\noindent
\textbf{KPTimes: A Large-Scale Dataset for Keyphrase Generation on News Documents.} \cite{gallina_kptimes_2019}\\
Ygor Gallina, Florian Boudin and Béatrice Daille%\\\cite{gallina_kptimes_2019}

\noindent
\textbf{Abstract:}
Keyphrase generation is the task of predicting a set of lexical units that conveys the main content of a source text. Existing datasets for keyphrase generation are only readily available for the scholarly domain and include non-expert annotations. In this paper we present KPTimes, a large-scale dataset of news texts paired with editor-curated keyphrases. Exploring the dataset, we show how editors tag documents, and how their annotations differ from those found in existing datasets. We also train and evaluate state-of-the-art neural keyphrase generation models on KPTimes to gain insights on how well they perform on the news domain. The dataset is available online at \url{https:// github.com/ygorg/KPTimes}.

\noindent
Publié dans les actes de la conférence \textit{Association for Computational Linguistics (\textsc{Acl})}.

\vspace{0.25cm}

\noindent\hfil\rule{0.5\textwidth}{.4pt}\hfil

\vspace{0.75cm}

\noindent
\textbf{Large-Scale Evaluation of Keyphrase Extraction Models.} \cite{gallina_large-scale_2020}\\
Ygor Gallina, Florian Boudin and Béatrice Daille%\\\cite{gallina_large-scale_2020}

\noindent
\textbf{Abstract:}
Keyphrase extraction models are usually evaluated under different, not directly comparable, experimental setups. As a result, it remains unclear how well proposed models actually perform, and how they compare to each other. In this work, we address this issue by presenting a systematic large-scale analysis of state-of-the-art keyphrase extraction models involving multiple benchmark datasets from various sources and domains. Our main results reveal that state-of-the-art models are in fact still challenged by simple baselines on some datasets. We also present new insights about the impact of using author- or reader-assigned keyphrases as a proxy for gold standard, and give recommendations for strong baselines and reliable benchmark datasets.

\noindent
Publié dans les actes de la conférence \textit{Joint Conference of Digital Libraries (\textsc{Jcdl})}.

\vspace{0.25cm}

\noindent\hfil\rule{0.5\textwidth}{.4pt}\hfil


\newpage

\noindent
\textbf{Keyphrase Generation for Scientific Document Retrieval.} \cite{boudin_keyphrase_2020}\\
Florian Boudin, Ygor Gallina and Akiko Aizawa%\\\cite{boudin_keyphrase_2020}

\noindent
\textbf{Abstract:}
Sequence-to-sequence models have lead to significant progress in keyphrase generation, but it remains unknown whether they are reliable enough to be beneficial for document retrieval. This study provides empirical evidence that such models can significantly improve retrieval performance, and introduces a new extrinsic evaluation framework that allows for a better understanding of the limitations of keyphrase generation models. Using this framework, we point out and discuss the difficulties encountered with supplementing documents with -not present in text- keyphrases, and generalizing models across domains. Our code is available at \url{https://github.com/boudinfl/ir-using-kg}.

\noindent
Publié dans les actes de la conférence \textit{Association for Computational Linguistics (\textsc{Acl})}.

%\vspace{0.05cm}

\noindent\hfil\rule{0.5\textwidth}{.4pt}\hfil

\vspace{0.2cm}

\noindent
\textbf{Redefining Absent Keyphrases and their Effect on Retrieval Effectiveness} \cite{boudin_redefining_2021}\\
Florian Boudin and Ygor Gallina%\\\cite{boudin_redefining_2021}

\noindent
\textbf{Abstract:}
Neural keyphrase generation models have recently attracted much interest due to their ability to output absent keyphrases, that is, keyphrases that do not appear in the source text. In this paper, we discuss the usefulness of absent keyphrases from an Information Retrieval (IR) perspective, and show that the commonly drawn distinction between present and absent keyphrases is not made explicit enough. We introduce a finer-grained categorization scheme that sheds more light on the impact of absent keyphrases on scientific document retrieval. Under this scheme, we find that only a fraction (around \npercent{20}) of the words that make up keyphrases actually serves as document expansion, but that this small fraction of words is behind much of the gains observed in retrieval effectiveness. We also discuss how the proposed scheme can offer a new angle to evaluate the output of neural keyphrase generation models.
\noindent
Publié dans les actes de la conférence \textit{Association for Computational Linguistics (\textsc{Acl})}.

\vspace{-0.6cm}

\section*{Publications en conférences nationales avec actes}
\addcontentsline{toc}{section}{Publications en conférences nationales avec actes}

\vspace{-0.2cm}

\noindent
\textbf{État de l'art des méthodes d'apprentissage profond pour l'extraction automatique de termes-clés} \cite{gallina_etat_2019}\\
Ygor Gallina%\\\cite{gallina_etat_2019}

\noindent
\textbf{Résumé~:}
Les termes-clés facilitent la recherche de documents dans de larges collections de données. Le coût d'annotation de document en termes-clés très élevé, c'est pourquoi les chercheurs s'intéressent à cette problématique. Dans cet article nous présentons un état de l'art sur l'extraction automatique de termes-clés en nous intéressant particulièrement aux modèles d'apprentissage profond. En effet, la récente publication d'un demi-million de documents annotés à permis le développement de modèles neuronaux profonds.

\noindent
Publié dans les actes de la Rencontre des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (\textsc{Recital}).